{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7078d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import scipy.stats as ss\n",
    "from statsmodels.api import ProbPlot\n",
    "\n",
    "warnings.filterwarnings(action = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b39bf443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Missing_Impute_MICE(data = None):\n",
    "    \"\"\"\n",
    "    impute the nan values of dataset with MICE \n",
    "    \"\"\"\n",
    "    imputer = IterativeImputer(estimator = LinearRegression(), max_iter=30, imputation_order = 'random')\n",
    "    imputer.fit(data)\n",
    "    data = imputer.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d5e55e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Missing_Detect_Diff_Distribution(data = None, col_A = None, col_B = None, col_C = None, method = 'count'):\n",
    "    \"\"\"\n",
    "    visualize the distribution of missing subset and not missing subset to find the difference\n",
    "    \"\"\"\n",
    "    missing_subset = data[data[col_A].isnull() == True]\n",
    "    notmissing_subset = data[data[col_A].isnull() == False]\n",
    "    \n",
    "    if method == 'count':\n",
    "        #col列缺失的数据子集\n",
    "        fig,ax = plt.subplots(1,2,figsize = (15,8))\n",
    "        sns.countplot(data = missing_subset,x = col_B,ax =ax[0])\n",
    "        ax[0].set_title(label = 'missing data set of {}'.format(col_A))\n",
    "\n",
    "        #col列非缺失值的数据子集\n",
    "        sns.countplot(data = notmissing_subset,x = col_B,ax =ax[1])\n",
    "        ax[1].set_title(label = 'not missing data set of {}'.format(col_A))\n",
    "\n",
    "        for idx in range(2):\n",
    "            bars = ax[idx].patches\n",
    "            half = int(len(bars)/2)\n",
    "            left_bars = bars[:half]\n",
    "            right_bars = bars[half:]\n",
    "\n",
    "            for left, right in zip(left_bars, right_bars):\n",
    "                height_l = left.get_height()\n",
    "                height_r = right.get_height()\n",
    "                total = height_l + height_r\n",
    "\n",
    "                ax[idx].text(left.get_x() + left.get_width() / 2., left.get_height(),'{0:.0%}'.format(height_l/total), ha=\"center\")\n",
    "                ax[idx].text(right.get_x() + right.get_width() / 2., right.get_height(),'{0:.0%}'.format(height_r/total), ha=\"center\")\n",
    "    elif method == 'scatter':\n",
    "        fig, ax = plt.subplots(1,2,figsize = (15,8))\n",
    "        #非缺失子集\n",
    "        sns.scatterplot(data = missing_subset, x = col_B, y= col_C, ax = ax[0])\n",
    "        ax[0].set_title(label = \"missing subset of {}\".format(col_A))\n",
    "        #缺失子集\n",
    "        sns.scatterplot(data = notmissing_subset, x = col_B, y = col_C, ax = ax[1])\n",
    "        ax[1].set_title(label = 'not missing subset of {}'.format(col_A))\n",
    "        \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    del missing_subset, notmissing_subset\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2977d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Missing_Imputer(data = None, col = None, method = \"mean\", fill_value = None):\n",
    "    \"\"\"\n",
    "    impute the missing value of data[col] with these methods of mean median mode and so on\n",
    "    \"\"\"\n",
    "    if method == 'constant':\n",
    "        imputer = SimpleImputer(strategy = method,fill_value=value)    \n",
    "    else:\n",
    "        imputer = SimpleImputer(strategy= method)\n",
    "    return imputer.fit_transform(data[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1026e93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Missing_Compute_Corr(data = None, col_A = None, col_B = None):\n",
    "    \"\"\"\n",
    "    compute the correlation of col_A and col_B\n",
    "    \"\"\"\n",
    "    notmissingsubset = data[~data[col_A].isnull()]\n",
    "    notmissingsubset = notmissingsubset[~notmissingsubset[col_B].isnull()]\n",
    "    \n",
    "    pearsonr_corr = ss.pearsonr(notmissingsubset[col_A], notmissingsubset[col_B])\n",
    "    print(\"the pearsonr corr between {} and {} is: {}\".format(col_A,col_B,pearsonr_corr))\n",
    "    \n",
    "    spearmanr_corr =  ss.spearmanr(notmissingsubset[col_A], notmissingsubset[col_B])\n",
    "    print(\"the spearmanr corr between {} and {} is: {}\".format(col_A, col_B,spearmanr_corr))\n",
    "    print('\\n')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acec0476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Outlier_Detect_IQR(data = None,  col = None):\n",
    "\n",
    "    \"\"\"\n",
    "    detect whether there are some outliers in a feature\n",
    "    \"\"\"\n",
    "    #Q1 Q3 mean and median values\n",
    "    Q1 = data[col].describe()['25%']\n",
    "    Q3 = data[col].describe()['75%']\n",
    "    mean_value = data[col].describe()['mean']\n",
    "    median_value = data[col].describe()['50%']\n",
    "    #calculate IQR\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    #1. calculate bound values  when median as the foundment value\n",
    "    upper_bound = median_value + 1.5 * IQR\n",
    "    lower_bound = median_value - 1.5 * IQR\n",
    "    #potentail outliers which above 1.5*IQR\n",
    "    potential_outliers_upper = pd.DataFrame(data = [x for x in data[col] if x > upper_bound],\n",
    "                                            columns=['outlier_above'])\n",
    "    potential_outliers_lower = pd.DataFrame(data  = [x for x in data[col] if x < lower_bound], \n",
    "                                            columns=['outlier_below'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"1. when median as the foundment value\\n\")\n",
    "    #above 1.5IQR specifical information\n",
    "    print(\"1.1 the upper bound value is {}\".format(upper_bound))\n",
    "    print(\"1.2 the potential outliers above 1.5IQR amount is : {}\".format(potential_outliers_upper.shape[0]))\n",
    "    print(\"1.3 the potential outliers above 1.5IQR values distribution is: \\n\", potential_outliers_upper.value_counts())\n",
    "    \n",
    "    #below 1.5IQR specifical information\n",
    "    print(\"1.4 the lower bound value is {}\".format(lower_bound))\n",
    "    print(\"1.5 the potential outliers below 1.5IQR amount is : {}\".format(potential_outliers_lower.shape[0]))\n",
    "    print(\"1.6 the potential outliers below 1.5IQR values distribution is: \\n\", potential_outliers_lower.value_counts())\n",
    "   \n",
    "    del potential_outliers_upper, potential_outliers_lower\n",
    "    gc.collect()\n",
    "   \n",
    "    #2. calculate bound values  when mean as the foundment value\n",
    "    upper_bound = mean_value + 1.5 * IQR\n",
    "    lower_bound = mean_value - 1.5 * IQR\n",
    "    #potentail outliers which above 1.5*IQR\n",
    "    potential_outliers_upper = pd.DataFrame(data = [x for x in data[col] if x > upper_bound], \n",
    "                                            columns=['outlier_above'])\n",
    "    potential_outliers_lower = pd.DataFrame(data  = [x for x in data[col] if x < lower_bound], \n",
    "                                            columns=['outlier_below'])\n",
    "    \n",
    "    print(100  * '-')\n",
    "    print(\"2. when mean as the foundment value\\n\")\n",
    "    #above 1.5IQR specifical information\n",
    "    print(\"2.1 the upper bound value is {}\".format(upper_bound))\n",
    "    print(\"2.2 the potential outliers above 1.5IQR amount is : {}\".format(potential_outliers_upper.shape[0]))\n",
    "    print(\"2.3 the potential outliers above 1.5IQR values distribution is: \\n\", potential_outliers_upper.value_counts())\n",
    "\n",
    "    #below 1.5IQR specifical information\n",
    "    \n",
    "    print(\"2.4 the lower bound is {}\".format(lower_bound))\n",
    "    print(\"2.5 the potential outliers below 1.5IQR amount is : {}\".format(potential_outliers_lower.shape[0]))\n",
    "    print(\"2.6 the potential outliers below 1.5IQR values distribution is: \\n\", potential_outliers_lower.value_counts())\n",
    "\n",
    "    del potential_outliers_upper, potential_outliers_lower\n",
    "    gc.collect()\n",
    "  \n",
    "    fig,ax = plt.subplots(1,3, figsize = (18,5))\n",
    "    sns.histplot(data = data, x = col, ax = ax[0])\n",
    "    \n",
    "    qqplot = ProbPlot(data[col])\n",
    "    qqplot.qqplot(line='s', ax = ax[1])\n",
    "\n",
    "    \n",
    "    sns.boxplot(data = data,y = col, ax = ax[2])\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44a318fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Outliers_Handle_Discretization(data = None, col = None, method  = 'median', value = -999999):\n",
    "    \"\"\"\n",
    "        handle Outliers by discretization method\n",
    "        @value_f :  the foundment value of IQR detection method, 'mean' or 'median'\n",
    "    \"\"\"\n",
    "        if method == 'mean':\n",
    "    #         value_f = np.mean(data[col])  will return nan value if data[col] contain nan value\n",
    "            value_f = np.nanmean(data[col])\n",
    "    #         value_f = data[col].quantile(q = 0.5)     this method also work well \n",
    "        else:\n",
    "    #         value_f = np.median(data[col])  will return nan value if data[col] contain nan value\n",
    "            value_f = np.nanmedian(data[col])\n",
    "\n",
    "        Q1 = data[col].quantile(q = 0.25)\n",
    "        Q3 = data[col].quantile(q = 0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        upper_bound = value_f + 1.5 * IQR\n",
    "        lower_bound = value_f - 1.5 * IQR\n",
    "\n",
    "        #find potential outlier  value\n",
    "        potential_outliers = [x for x in data[col] if x > upper_bound or x < lower_bound]\n",
    "        #remove duplicate values\n",
    "        potential_outliers = set(potential_outliers)\n",
    "\n",
    "        #discretize outliers into a single value,eg:999999,-999999\n",
    "        data[col] = data[col].apply(lambda x : value if x in potential_outliers else x)\n",
    "\n",
    "        return data[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5d276ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rare_Value_Handle(data = None, col = None, method = 'mode', t = 100):\n",
    "    \"\"\"\n",
    "        feature may has some rare values\n",
    "        accodrding to needness, we can impute rare values with mode value impute or classify them to class 'other'\n",
    "        \n",
    "        t is the threshold of rare value which need to be handled. its default value is 100 what means total num of \n",
    "        some value  is less 100 \n",
    "    \"\"\"\n",
    "    rare_value_list = list((data[col].value_counts() < t).index)\n",
    "    if method == \"mode\":\n",
    "        #mode value may not be unique, so ,we choose the first value as mode\n",
    "        mode_value = data[col].mode()[0]\n",
    "        data[col] = data[col].apply(lambda x : mode_value  if x in rare_value_list  else x)\n",
    "    else:\n",
    "        #we choose a specifical value as a class of featue. The default value may be 9999or -9999\n",
    "        data[col] = data[col].apply(lambda x : 9999 if x in rare_value_list  else x)\n",
    "    \n",
    "    return data[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9c4fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646a9725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bdf0a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ef6588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6f4e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
